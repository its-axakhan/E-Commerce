{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f826fb8d",
   "metadata": {},
   "source": [
    "# 0. Imports, Install (if needed) & Config\n",
    "\n",
    "\n",
    " If you don't need installs, you can comment this cell out.\n",
    " Make sure you're using the same Python env as your previous notebook.\n",
    "\n",
    " !pip install pandas pyarrow numpy fastparquet scikit-learn rank-bm25 lightgbm datasets transformers sentencepiece einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de26e845-0ed9-405c-ae2e-d3040b63a385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:43:41.466509Z",
     "iopub.status.busy": "2025-11-25T02:43:41.466115Z",
     "iopub.status.idle": "2025-11-25T02:43:41.473474Z",
     "shell.execute_reply": "2025-11-25T02:43:41.472919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/modules/devel/python/3.11.11/bin/python\n",
      "\n",
      "Filtered sys.path (no python3.8 entries):\n",
      "  \n",
      "  /mnt/ceph/bibi8250/E-commerce\n",
      "  /opt/modules/devel/python/3.11.11/lib/python311.zip\n",
      "  /opt/modules/devel/python/3.11.11/lib/python3.11\n",
      "  /opt/modules/devel/python/3.11.11/lib/python3.11/lib-dynload\n",
      "  /mnt/ceph/bibi8250/.local/lib/python3.11/site-packages\n",
      "  /opt/modules/devel/python/3.11.11/lib/python3.11/site-packages\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "sys.path = [p for p in sys.path if \"python3.8\" not in p]\n",
    "\n",
    "print(\"\\nFiltered sys.path (no python3.8 entries):\")\n",
    "for p in sys.path:\n",
    "    print(\" \", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f7bf81-17e5-4d63-a9e5-4cb4a99d83fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:43:41.475140Z",
     "iopub.status.busy": "2025-11-25T02:43:41.474983Z",
     "iopub.status.idle": "2025-11-25T02:44:49.298619Z",
     "shell.execute_reply": "2025-11-25T02:44:49.297832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/modules/devel/python/3.11.11/bin/python\n",
      "\n",
      "ALL CODE-CRITICAL IMPORTS LOADED OK\n",
      "\n",
      "numpy: 1.26.4\n",
      "pandas: 2.3.3\n",
      "sklearn: 1.7.2\n",
      "rank_bm25: <class 'rank_bm25.BM25Okapi'>\n",
      "lightgbm: 4.6.0\n",
      "torch: 2.5.1+cu121\n",
      "pyarrow: 22.0.0\n",
      "datasets: 4.4.1\n",
      "transformers: 4.57.1\n",
      "huggingface_hub: 0.36.0\n",
      "tokenizers: 0.22.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from rank_bm25 import BM25Okapi\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import pyarrow\n",
    "import datasets\n",
    "import transformers\n",
    "import huggingface_hub\n",
    "import tokenizers\n",
    "\n",
    "print(\"\\nALL CODE-CRITICAL IMPORTS LOADED OK\\n\")\n",
    "\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"rank_bm25:\", BM25Okapi)\n",
    "print(\"lightgbm:\", lgb.__version__)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"pyarrow:\", pyarrow.__version__)\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"huggingface_hub:\", huggingface_hub.__version__)\n",
    "print(\"tokenizers:\", tokenizers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3936fe33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:44:49.301044Z",
     "iopub.status.busy": "2025-11-25T02:44:49.300598Z",
     "iopub.status.idle": "2025-11-25T02:46:01.638352Z",
     "shell.execute_reply": "2025-11-25T02:46:01.637617Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 18:45:11.812867: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "import lightgbm as lgb\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "# ---- CONFIG ----\n",
    "DATA_ROOT    = Path(\"esci_pipeline/data_ru\")\n",
    "PATH_TRAIN   = DATA_ROOT / \"esci_train.parquet\"\n",
    "PATH_TEST    = DATA_ROOT / \"esci_test.parquet\"\n",
    "\n",
    "LOCALE       = \"us\"  # change later for \"es\", \"jp\", etc.\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Models\n",
    "GTE_MODEL_NAME  = \"Alibaba-NLP/gte-multilingual-base\"\n",
    "XENC_MODEL_NAME = \"distilbert-base-multilingual-cased\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "# ---- PERSISTENCE CONFIG ----\n",
    "ARTIFACT_DIR = Path(\"esci_pipeline/artifacts_ru\")\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PATH_TRAIN_PREP = ARTIFACT_DIR / \"train_df_prepared.parquet\"\n",
    "PATH_VALID_PREP = ARTIFACT_DIR / \"valid_df_prepared.parquet\"\n",
    "PATH_PROD_EMBS  = ARTIFACT_DIR / \"prod_embs.npy\"\n",
    "PATH_PROD_IDS   = ARTIFACT_DIR / \"product_ids.npy\"\n",
    "PATH_BM25_PKL   = ARTIFACT_DIR / \"bm25_corpus.pkl\"\n",
    "PATH_LGB_MODEL  = ARTIFACT_DIR / \"ltr_model_us.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0705d784",
   "metadata": {},
   "source": [
    "# 1. Load & Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae92450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:46:01.641218Z",
     "iopub.status.busy": "2025-11-25T02:46:01.640314Z",
     "iopub.status.idle": "2025-11-25T02:46:43.498026Z",
     "shell.execute_reply": "2025-11-25T02:46:43.497221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shapes: (2027874, 14) (652490, 14)\n",
      "Locales train:\n",
      " product_locale\n",
      "us    1420372\n",
      "jp     333112\n",
      "es     274390\n",
      "Name: count, dtype: int64\n",
      "Cleaned shapes: (1420372, 14) (434234, 14)\n",
      "Relevance distribution (train):\n",
      "relevance\n",
      "0    122273\n",
      "1     29713\n",
      "2    280324\n",
      "3    988062\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Load ESCI train/test\n",
    "esci_train = pd.read_parquet(PATH_TRAIN)\n",
    "esci_test  = pd.read_parquet(PATH_TEST)\n",
    "\n",
    "print(\"Raw shapes:\", esci_train.shape, esci_test.shape)\n",
    "print(\"Locales train:\\n\", esci_train[\"product_locale\"].value_counts())\n",
    "\n",
    "# 1.2 Filter to locale (US for now)\n",
    "esci_train = esci_train[esci_train[\"product_locale\"] == LOCALE].copy()\n",
    "esci_test  = esci_test[esci_test[\"product_locale\"] == LOCALE].copy()\n",
    "\n",
    "# 1.3 Drop rows with missing query/title\n",
    "esci_train = esci_train.dropna(subset=[\"query\", \"product_title\"])\n",
    "esci_test  = esci_test.dropna(subset=[\"query\", \"product_title\"])\n",
    "\n",
    "# 1.4 Fill remaining text NaNs\n",
    "text_cols = [\n",
    "    \"product_description\",\n",
    "    \"product_bullet_point\",\n",
    "    \"product_brand\",\n",
    "    \"product_color\",\n",
    "    \"product_text\",\n",
    "]\n",
    "\n",
    "for col in text_cols:\n",
    "    esci_train[col] = esci_train[col].fillna(\"\")\n",
    "    esci_test[col]  = esci_test[col].fillna(\"\")\n",
    "\n",
    "print(\"Cleaned shapes:\", esci_train.shape, esci_test.shape)\n",
    "\n",
    "# 1.5 Map ESCI labels to numeric relevance 0–3\n",
    "label2rel = {\n",
    "    \"Irrelevant\": 0,\n",
    "    \"Complement\": 1,\n",
    "    \"Substitute\": 2,\n",
    "    \"Exact\": 3,\n",
    "}\n",
    "\n",
    "esci_train[\"relevance\"] = esci_train[\"esci_label\"].map(label2rel).astype(\"int8\")\n",
    "esci_test[\"relevance\"]  = esci_test[\"esci_label\"].map(label2rel).astype(\"int8\")\n",
    "\n",
    "print(\"Relevance distribution (train):\")\n",
    "print(esci_train[\"relevance\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acda5ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:46:43.500206Z",
     "iopub.status.busy": "2025-11-25T02:46:43.500013Z",
     "iopub.status.idle": "2025-11-25T02:47:17.253960Z",
     "shell.execute_reply": "2025-11-25T02:47:17.253228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full US label counts:\n",
      " relevance\n",
      "0    122273\n",
      "1     29713\n",
      "2    280324\n",
      "3    988062\n",
      "Name: count, dtype: int64\n",
      "Ideal per-class target: 50000\n",
      "⚠ Smallest class only has 29713 examples; using n_per_class=29713 (total=118852) instead of full 50,000.\n",
      "Using n_per_class = 29713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3919545/1815475923.py:32: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(n=n_per_class, random_state=RANDOM_STATE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced subset shape: (118852, 15)\n",
      "relevance\n",
      "0    29713\n",
      "1    29713\n",
      "2    29713\n",
      "3    29713\n",
      "Name: count, dtype: int64\n",
      "Saved balanced subset to: esci_pipeline/data_ru/esci_us_balanced_200k.parquet\n"
     ]
    }
   ],
   "source": [
    "# ---- Balanced 200k subset of US ESCI (by relevance) ----\n",
    "DESIRED_TOTAL = 200_000\n",
    "LABEL_COL = \"relevance\"\n",
    "\n",
    "# Check class distribution\n",
    "label_counts = esci_train[LABEL_COL].value_counts().sort_index()\n",
    "print(\"Full US label counts:\\n\", label_counts)\n",
    "\n",
    "num_classes = label_counts.shape[0]\n",
    "\n",
    "# Ideal per-class target (for 200k total)\n",
    "ideal_per_class = DESIRED_TOTAL // num_classes\n",
    "print(\"Ideal per-class target:\", ideal_per_class)\n",
    "\n",
    "# But make sure we don't ask more than the smallest class has\n",
    "min_available = label_counts.min()\n",
    "n_per_class = min(ideal_per_class, min_available)\n",
    "\n",
    "if n_per_class < ideal_per_class:\n",
    "    print(\n",
    "        f\"⚠ Smallest class only has {min_available} examples; \"\n",
    "        f\"using n_per_class={n_per_class} (total={n_per_class * num_classes}) \"\n",
    "        f\"instead of full 50,000.\"\n",
    "    )\n",
    "\n",
    "print(\"Using n_per_class =\", n_per_class)\n",
    "\n",
    "# Sample a balanced subset\n",
    "esci_train_balanced = (\n",
    "    esci_train\n",
    "    .groupby(LABEL_COL, group_keys=False)\n",
    "    .apply(lambda g: g.sample(n=n_per_class, random_state=RANDOM_STATE))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Balanced subset shape:\", esci_train_balanced.shape)\n",
    "print(esci_train_balanced[LABEL_COL].value_counts().sort_index())\n",
    "\n",
    "# Optionally save for translation / reuse\n",
    "BALANCED_PATH = DATA_ROOT / \"esci_us_balanced_200k.parquet\"\n",
    "esci_train_balanced.to_parquet(BALANCED_PATH, index=False)\n",
    "print(\"Saved balanced subset to:\", BALANCED_PATH)\n",
    "\n",
    "esci_train = esci_train_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71acf2c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:47:17.255884Z",
     "iopub.status.busy": "2025-11-25T02:47:17.255709Z",
     "iopub.status.idle": "2025-11-25T02:47:32.460059Z",
     "shell.execute_reply": "2025-11-25T02:47:32.459213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved for translation: esci_pipeline/data_ru/us_balanced_200k_for_translation.parquet\n"
     ]
    }
   ],
   "source": [
    "# Export only the fields needed for translation\n",
    "to_translate = esci_train_balanced[[\n",
    "    \"example_id\",\n",
    "    \"query\",\n",
    "    \"product_title\",\n",
    "    \"product_description\",\n",
    "    \"product_bullet_point\",\n",
    "    \"product_brand\",\n",
    "    \"product_color\",\n",
    "    \"relevance\",\n",
    "    \"product_id\",\n",
    "    \"query_id\",\n",
    "]].copy()\n",
    "\n",
    "to_translate_path = DATA_ROOT / \"us_balanced_200k_for_translation.parquet\"\n",
    "to_translate.to_parquet(to_translate_path, index=False)\n",
    "\n",
    "print(\"Saved for translation:\", to_translate_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaaa8ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:47:32.461958Z",
     "iopub.status.busy": "2025-11-25T02:47:32.461775Z",
     "iopub.status.idle": "2025-11-25T02:47:37.567425Z",
     "shell.execute_reply": "2025-11-25T02:47:37.566713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full US TEST label counts:\n",
      " relevance\n",
      "0     43505\n",
      "1     11147\n",
      "2     97163\n",
      "3    282419\n",
      "Name: count, dtype: int64\n",
      "Ideal per-class target (test): 10000\n",
      "Using n_per_class_test = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3919545/1345452412.py:28: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(n=n_per_class_test, random_state=RANDOM_STATE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced TEST subset shape: (40000, 15)\n",
      "relevance\n",
      "0    10000\n",
      "1    10000\n",
      "2    10000\n",
      "3    10000\n",
      "Name: count, dtype: int64\n",
      "Saved TEST subset for translation: esci_pipeline/data_ru/us_test_balanced_for_translation.parquet\n"
     ]
    }
   ],
   "source": [
    "# ---- Balanced 40k subset of US ESCI TEST (by relevance) ----\n",
    "DESIRED_TEST = 40_000    # change to 5_000 if you prefer\n",
    "LABEL_COL_TEST = \"relevance\"\n",
    "\n",
    "# Check class distribution in test\n",
    "label_counts_test = esci_test[LABEL_COL_TEST].value_counts().sort_index()\n",
    "print(\"Full US TEST label counts:\\n\", label_counts_test)\n",
    "\n",
    "num_classes_test = label_counts_test.shape[0]\n",
    "ideal_per_class_test = DESIRED_TEST // num_classes_test\n",
    "print(\"Ideal per-class target (test):\", ideal_per_class_test)\n",
    "\n",
    "min_available_test = label_counts_test.min()\n",
    "n_per_class_test = min(ideal_per_class_test, min_available_test)\n",
    "\n",
    "if n_per_class_test < ideal_per_class_test:\n",
    "    print(\n",
    "        f\"⚠ Smallest test class only has {min_available_test} examples; \"\n",
    "        f\"using n_per_class_test={n_per_class_test} \"\n",
    "        f\"(total={n_per_class_test * num_classes_test}) instead of full {DESIRED_TEST}.\"\n",
    "    )\n",
    "\n",
    "print(\"Using n_per_class_test =\", n_per_class_test)\n",
    "\n",
    "esci_test_balanced = (\n",
    "    esci_test\n",
    "    .groupby(LABEL_COL_TEST, group_keys=False)\n",
    "    .apply(lambda g: g.sample(n=n_per_class_test, random_state=RANDOM_STATE))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Balanced TEST subset shape:\", esci_test_balanced.shape)\n",
    "print(esci_test_balanced[LABEL_COL_TEST].value_counts().sort_index())\n",
    "\n",
    "# Export only the fields needed for translation\n",
    "test_to_translate = esci_test_balanced[[\n",
    "    \"example_id\",\n",
    "    \"query\",\n",
    "    \"product_title\",\n",
    "    \"product_description\",\n",
    "    \"product_bullet_point\",\n",
    "    \"product_brand\",\n",
    "    \"product_color\",\n",
    "    \"relevance\",\n",
    "    \"product_id\",\n",
    "    \"query_id\",\n",
    "]].copy()\n",
    "\n",
    "test_to_translate_path = DATA_ROOT / \"us_test_balanced_for_translation.parquet\"\n",
    "test_to_translate.to_parquet(test_to_translate_path, index=False)\n",
    "\n",
    "print(\"Saved TEST subset for translation:\", test_to_translate_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15af1f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T02:47:37.569415Z",
     "iopub.status.busy": "2025-11-25T02:47:37.569236Z",
     "iopub.status.idle": "2025-11-25T06:36:31.460235Z",
     "shell.execute_reply": "2025-11-25T06:36:31.459592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded for translation: (118852, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translating column: query\n",
      "Done: query 118432/118852 rows\n",
      "\n",
      "Translating column: product_title\n",
      "Done: product_title118852 rows\n",
      "\n",
      "Translating column: product_description\n",
      "Done: product_description rows\n",
      "\n",
      "Translating column: product_bullet_point\n",
      "Done: product_bullet_pointrows\n",
      "\n",
      "Translating column: product_brand\n",
      "Done: product_brand118852 rows\n",
      "\n",
      "Translating column: product_color\n",
      "Done: product_color118852 rows\n",
      "\n",
      "Saved Russian-translated dataset to: esci_pipeline/data_ru/esci_ru_balanced_200k.parquet\n",
      "Shape: (118852, 10)\n",
      "Label distribution:\n",
      " relevance\n",
      "0    29713\n",
      "1    29713\n",
      "2    29713\n",
      "3    29713\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1.X Translate balanced US subset to Russian\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the same data we just saved (for reproducibility)\n",
    "to_translate_path = DATA_ROOT / \"us_balanced_200k_for_translation.parquet\"\n",
    "df_src = pd.read_parquet(to_translate_path)\n",
    "print(\"Loaded for translation:\", df_src.shape)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "MT_MODEL_NAME = \"Helsinki-NLP/opus-mt-en-ru\"  # EN → RU\n",
    "\n",
    "\n",
    "mt_tokenizer = AutoTokenizer.from_pretrained(MT_MODEL_NAME)\n",
    "mt_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MT_MODEL_NAME,\n",
    "    use_safetensors=True,     # <- avoids the torch.load vulnerability path\n",
    "    torch_dtype=torch.float32 # safe default\n",
    ").to(DEVICE)\n",
    "mt_model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def translate_batch(texts, max_length=128):\n",
    "    \"\"\"\n",
    "    Translate a list of English strings to Russian.\n",
    "    Empty strings stay empty.\n",
    "    \"\"\"\n",
    "    if all((t is None or t == \"\") for t in texts):\n",
    "        return [\"\" for _ in texts]\n",
    "\n",
    "    texts = [(t if t is not None else \"\") for t in texts]\n",
    "\n",
    "    enc = mt_tokenizer(\n",
    "        texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    gen = mt_model.generate(\n",
    "        **enc,\n",
    "        max_length=max_length,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    out = mt_tokenizer.batch_decode(gen, skip_special_tokens=True)\n",
    "\n",
    "    if len(out) < len(texts):\n",
    "        out += [\"\"] * (len(texts) - len(out))\n",
    "    return out\n",
    "\n",
    "# ---- Apply translation column-wise ----\n",
    "cols_to_translate = [\n",
    "    \"query\",\n",
    "    \"product_title\",\n",
    "    \"product_description\",\n",
    "    \"product_bullet_point\",\n",
    "    \"product_brand\",\n",
    "    \"product_color\",\n",
    "]\n",
    "\n",
    "df_ru = df_src.copy()\n",
    "BATCH_SIZE = 32  \n",
    "\n",
    "for col in cols_to_translate:\n",
    "    print(f\"\\nTranslating column: {col}\")\n",
    "    src_col = df_src[col].fillna(\"\").astype(str)\n",
    "    translated = []\n",
    "\n",
    "    for start in range(0, len(src_col), BATCH_SIZE):\n",
    "        batch = src_col.iloc[start:start + BATCH_SIZE].tolist()\n",
    "        ru_batch = translate_batch(batch, max_length=128)\n",
    "        translated.extend(ru_batch)\n",
    "\n",
    "        if (start // BATCH_SIZE) % 50 == 0:\n",
    "            print(f\"  processed {start + len(batch)}/{len(src_col)} rows\", end=\"\\r\")\n",
    "\n",
    "    df_ru[col] = translated\n",
    "    print(f\"Done: {col}\")\n",
    "\n",
    "# ---- Add locale + label text for RU pipeline compatibility ----\n",
    "# df_ru[\"product_locale\"] = \"ru\"\n",
    "# label_map_inv = {0: \"Irrelevant\", 1: \"Complement\", 2: \"Substitute\", 3: \"Exact\"}\n",
    "# df_ru[\"esci_label\"] = df_ru[\"relevance\"].map(label_map_inv)\n",
    "\n",
    "# ---- Save Russian-translated dataset ----\n",
    "RU_PATH = DATA_ROOT / \"esci_ru_balanced_200k.parquet\"\n",
    "df_ru.to_parquet(RU_PATH, index=False)\n",
    "print(\"\\nSaved Russian-translated dataset to:\", RU_PATH)\n",
    "# USE THE TRANSLATED RUSSIAN DATA FROM THIS POINT FORWARD\n",
    "esci_train = df_ru.copy()\n",
    "print(\"Shape:\", df_ru.shape)\n",
    "print(\"Label distribution:\\n\", df_ru[\"relevance\"].value_counts().sort_index())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08de8368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T06:36:31.462341Z",
     "iopub.status.busy": "2025-11-25T06:36:31.462165Z",
     "iopub.status.idle": "2025-11-25T06:36:33.180323Z",
     "shell.execute_reply": "2025-11-25T06:36:33.179777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilt RU TRAIN shape: (118852, 12)\n",
      "RU TRAIN columns: ['example_id', 'query', 'product_title', 'product_description', 'product_bullet_point', 'product_brand', 'product_color', 'relevance', 'product_id', 'query_id', 'product_locale', 'esci_label']\n"
     ]
    }
   ],
   "source": [
    "# Adding remaining columns\n",
    "# 1. Load original balanced US dataset used for translation\n",
    "us_train_balanced_path = DATA_ROOT / \"us_balanced_200k_for_translation.parquet\"\n",
    "df_us_train = pd.read_parquet(us_train_balanced_path)\n",
    "\n",
    "# 2. Load text-only RU translation (just Russian text)\n",
    "df_ru_text = esci_train.copy()       # this is df_ru you just created\n",
    "\n",
    "# Sanity: ensure they have same row count\n",
    "assert df_us_train.shape[0] == df_ru_text.shape[0], \"Row count mismatch!\"\n",
    "\n",
    "# 3. Rebuild complete RU dataset by replacing text columns\n",
    "cols_to_translate = [\n",
    "    \"query\",\n",
    "    \"product_title\",\n",
    "    \"product_description\",\n",
    "    \"product_bullet_point\",\n",
    "    \"product_brand\",\n",
    "    \"product_color\",\n",
    "]\n",
    "\n",
    "df_ru_full = df_us_train.copy()\n",
    "for col in cols_to_translate:\n",
    "    df_ru_full[col] = df_ru_text[col].astype(str)\n",
    "\n",
    "# Add locale + label if needed\n",
    "df_ru_full[\"product_locale\"] = \"ru\"\n",
    "df_ru_full[\"esci_label\"] = df_ru_full[\"relevance\"].map({\n",
    "    0: \"Irrelevant\",\n",
    "    1: \"Complement\",\n",
    "    2: \"Substitute\",\n",
    "    3: \"Exact\",\n",
    "})\n",
    "\n",
    "print(\"Rebuilt RU TRAIN shape:\", df_ru_full.shape)\n",
    "print(\"RU TRAIN columns:\", df_ru_full.columns.tolist())\n",
    "\n",
    "# IMPORTANT: overwrite esci_train with rebuilt dataset\n",
    "esci_train = df_ru_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda2c4e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T06:36:33.182043Z",
     "iopub.status.busy": "2025-11-25T06:36:33.181876Z",
     "iopub.status.idle": "2025-11-25T07:53:57.893260Z",
     "shell.execute_reply": "2025-11-25T07:53:57.892615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TEST subset for translation: (40000, 10)\n",
      "\n",
      "Translating TEST column: query\n",
      "Done: query 39712/40000 rows\n",
      "\n",
      "Translating TEST column: product_title\n",
      "Done: product_title0000 rows\n",
      "\n",
      "Translating TEST column: product_description\n",
      "Done: product_descriptionows\n",
      "\n",
      "Translating TEST column: product_bullet_point\n",
      "Done: product_bullet_pointws\n",
      "\n",
      "Translating TEST column: product_brand\n",
      "Done: product_brand0000 rows\n",
      "\n",
      "Translating TEST column: product_color\n",
      "Done: product_color0000 rows\n",
      "\n",
      "Saved Russian TEST dataset to: esci_pipeline/data_ru/esci_ru_test_balanced.parquet\n",
      "RU TEST shape: (40000, 10)\n",
      "RU TEST label distribution:\n",
      " relevance\n",
      "0    10000\n",
      "1    10000\n",
      "2    10000\n",
      "3    10000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---- Load the TEST subset we just saved ----\n",
    "test_to_translate_path = DATA_ROOT / \"us_test_balanced_for_translation.parquet\"\n",
    "df_test_src = pd.read_parquet(test_to_translate_path)\n",
    "print(\"Loaded TEST subset for translation:\", df_test_src.shape)\n",
    "\n",
    "cols_to_translate = [\n",
    "    \"query\",\n",
    "    \"product_title\",\n",
    "    \"product_description\",\n",
    "    \"product_bullet_point\",\n",
    "    \"product_brand\",\n",
    "    \"product_color\",\n",
    "]\n",
    "\n",
    "df_test_ru = df_test_src.copy()\n",
    "BATCH_SIZE = 32   \n",
    "\n",
    "for col in cols_to_translate:\n",
    "    print(f\"\\nTranslating TEST column: {col}\")\n",
    "    src_col = df_test_src[col].fillna(\"\").astype(str)\n",
    "    translated = []\n",
    "\n",
    "    for start in range(0, len(src_col), BATCH_SIZE):\n",
    "        batch = src_col.iloc[start:start + BATCH_SIZE].tolist()\n",
    "        ru_batch = translate_batch(batch, max_length=128)\n",
    "        translated.extend(ru_batch)\n",
    "\n",
    "        # light progress log\n",
    "        if (start // BATCH_SIZE) % 20 == 0:\n",
    "            print(f\"  processed {start + len(batch)}/{len(src_col)} rows\", end=\"\\r\")\n",
    "\n",
    "    df_test_ru[col] = translated\n",
    "    print(f\"Done: {col}\")\n",
    "\n",
    "# ---- Add locale + esci_label for RU test ----\n",
    "#df_test_ru[\"product_locale\"] = \"ru\"\n",
    "#label_map_inv = {0: \"Irrelevant\", 1: \"Complement\", 2: \"Substitute\", 3: \"Exact\"}\n",
    "#df_test_ru[\"esci_label\"] = df_test_ru[\"relevance\"].map(label_map_inv)\n",
    "\n",
    "# ---- Save Russian TEST dataset ----\n",
    "RU_TEST_PATH = DATA_ROOT / \"esci_ru_test_balanced.parquet\"\n",
    "df_test_ru.to_parquet(RU_TEST_PATH, index=False)\n",
    "\n",
    "print(\"\\nSaved Russian TEST dataset to:\", RU_TEST_PATH)\n",
    "esci_test = df_test_ru.copy()\n",
    "print(\"RU TEST shape:\", df_test_ru.shape)\n",
    "print(\"RU TEST label distribution:\\n\", df_test_ru[\"relevance\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d14375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:53:57.895332Z",
     "iopub.status.busy": "2025-11-25T07:53:57.895158Z",
     "iopub.status.idle": "2025-11-25T07:53:58.554977Z",
     "shell.execute_reply": "2025-11-25T07:53:58.554431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilt RU TEST shape: (40000, 12)\n",
      "RU TEST columns: ['example_id', 'query', 'product_title', 'product_description', 'product_bullet_point', 'product_brand', 'product_color', 'relevance', 'product_id', 'query_id', 'product_locale', 'esci_label']\n"
     ]
    }
   ],
   "source": [
    "# Load original US TEST balanced dataset (with metadata)\n",
    "us_test_balanced_path = DATA_ROOT / \"us_test_balanced_for_translation.parquet\"\n",
    "df_us_test = pd.read_parquet(us_test_balanced_path)\n",
    "\n",
    "# Load text-only RU translation for TEST\n",
    "df_ru_test_text = esci_test.copy()\n",
    "\n",
    "# Sanity\n",
    "assert df_us_test.shape[0] == df_ru_test_text.shape[0], \"Row mismatch in TEST!\"\n",
    "\n",
    "# Replace only translated text columns\n",
    "cols_to_translate = [\n",
    "    \"query\",\n",
    "    \"product_title\",\n",
    "    \"product_description\",\n",
    "    \"product_bullet_point\",\n",
    "    \"product_brand\",\n",
    "    \"product_color\",\n",
    "]\n",
    "\n",
    "df_ru_test_full = df_us_test.copy()\n",
    "for col in cols_to_translate:\n",
    "    df_ru_test_full[col] = df_ru_test_text[col].astype(str)\n",
    "\n",
    "df_ru_test_full[\"product_locale\"] = \"ru\"\n",
    "df_ru_test_full[\"esci_label\"] = df_ru_test_full[\"relevance\"].map({\n",
    "    0: \"Irrelevant\",\n",
    "    1: \"Complement\",\n",
    "    2: \"Substitute\",\n",
    "    3: \"Exact\",\n",
    "})\n",
    "\n",
    "print(\"Rebuilt RU TEST shape:\", df_ru_test_full.shape)\n",
    "print(\"RU TEST columns:\", df_ru_test_full.columns.tolist())\n",
    "\n",
    "# Overwrite esci_test\n",
    "esci_test = df_ru_test_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4582f642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:53:58.556747Z",
     "iopub.status.busy": "2025-11-25T07:53:58.556587Z",
     "iopub.status.idle": "2025-11-25T07:54:12.193730Z",
     "shell.execute_reply": "2025-11-25T07:54:12.193148Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_ru(text: str) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Keep digits, Latin letters, and Cyrillic (а-я ё); remove other junk\n",
    "    text = re.sub(r\"[^0-9a-zа-яё]+\", \" \", text, flags=re.IGNORECASE)\n",
    "    # Collapse spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "RU_TEXT_COLS = [\n",
    "    \"query\",\n",
    "    \"product_title\",\n",
    "    \"product_description\",\n",
    "    \"product_bullet_point\",\n",
    "    \"product_brand\",\n",
    "    \"product_color\",\n",
    "]\n",
    "\n",
    "for col in RU_TEXT_COLS:\n",
    "    esci_train[col] = esci_train[col].astype(str).map(normalize_ru)\n",
    "    esci_test[col]  = esci_test[col].astype(str).map(normalize_ru)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ad80af",
   "metadata": {},
   "source": [
    "# 2. Unified Text + Explicit Context Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69509aca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:54:12.195976Z",
     "iopub.status.busy": "2025-11-25T07:54:12.195805Z",
     "iopub.status.idle": "2025-11-25T07:54:17.243426Z",
     "shell.execute_reply": "2025-11-25T07:54:17.242910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_bullet_point</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>product_color</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>...</th>\n",
       "      <th>ctx_title_len</th>\n",
       "      <th>ctx_desc_len</th>\n",
       "      <th>ctx_bullet_len</th>\n",
       "      <th>ctx_brand_in_title</th>\n",
       "      <th>ctx_color_in_title</th>\n",
       "      <th>prod_count</th>\n",
       "      <th>prod_mean_rel</th>\n",
       "      <th>prod_max_rel</th>\n",
       "      <th>query_count</th>\n",
       "      <th>query_mean_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193260</td>\n",
       "      <td>amazon com код активирован</td>\n",
       "      <td>хулу</td>\n",
       "      <td>я не знаю что делать</td>\n",
       "      <td>получите неограниченный мгновенный доступ к ог...</td>\n",
       "      <td>гулу</td>\n",
       "      <td>я не знаю что делать</td>\n",
       "      <td>0</td>\n",
       "      <td>B0066TUXU6</td>\n",
       "      <td>8677</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>264260</td>\n",
       "      <td>браслет для малышки</td>\n",
       "      <td>quot goldenchen mealshion juelry 925 quot сере...</td>\n",
       "      <td>голденхен лидер модных ювелирных изделий котор...</td>\n",
       "      <td>высококачественный медный материал без вредных...</td>\n",
       "      <td>золотая кухня</td>\n",
       "      <td>серебро</td>\n",
       "      <td>0</td>\n",
       "      <td>B07663TBC4</td>\n",
       "      <td>12307</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1311389</td>\n",
       "      <td>макс японский</td>\n",
       "      <td>макс ваимо hd 11flk flat clinch stapler с трем...</td>\n",
       "      <td>я не знаю что делать</td>\n",
       "      <td>качественный плоский степлер для 35 листов бум...</td>\n",
       "      <td>макс япония</td>\n",
       "      <td>разряд</td>\n",
       "      <td>0</td>\n",
       "      <td>B06Y1CBVKT</td>\n",
       "      <td>66517</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1632982</td>\n",
       "      <td>моющее масло под давлением</td>\n",
       "      <td>охранник стирального насоса simpson</td>\n",
       "      <td>я не знаю что делать</td>\n",
       "      <td>предназначенная для установки большинства омыв...</td>\n",
       "      <td>симпсон уборка</td>\n",
       "      <td>оригинал</td>\n",
       "      <td>0</td>\n",
       "      <td>B004S67CUS</td>\n",
       "      <td>83198</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300511</td>\n",
       "      <td>пляжные шляпы для женщин</td>\n",
       "      <td>один кислота боженного винного вина красный l</td>\n",
       "      <td>для того чтобы внушить уверенность и красоту с...</td>\n",
       "      <td>дизайн halter neck loop strap detail ruged sid...</td>\n",
       "      <td>следует</td>\n",
       "      <td>вино красное</td>\n",
       "      <td>0</td>\n",
       "      <td>B072BJPTKJ</td>\n",
       "      <td>14164</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_id                       query  \\\n",
       "0      193260  amazon com код активирован   \n",
       "1      264260         браслет для малышки   \n",
       "2     1311389               макс японский   \n",
       "3     1632982  моющее масло под давлением   \n",
       "4      300511    пляжные шляпы для женщин   \n",
       "\n",
       "                                       product_title  \\\n",
       "0                                               хулу   \n",
       "1  quot goldenchen mealshion juelry 925 quot сере...   \n",
       "2  макс ваимо hd 11flk flat clinch stapler с трем...   \n",
       "3                охранник стирального насоса simpson   \n",
       "4      один кислота боженного винного вина красный l   \n",
       "\n",
       "                                 product_description  \\\n",
       "0                               я не знаю что делать   \n",
       "1  голденхен лидер модных ювелирных изделий котор...   \n",
       "2                               я не знаю что делать   \n",
       "3                               я не знаю что делать   \n",
       "4  для того чтобы внушить уверенность и красоту с...   \n",
       "\n",
       "                                product_bullet_point   product_brand  \\\n",
       "0  получите неограниченный мгновенный доступ к ог...            гулу   \n",
       "1  высококачественный медный материал без вредных...   золотая кухня   \n",
       "2  качественный плоский степлер для 35 листов бум...     макс япония   \n",
       "3  предназначенная для установки большинства омыв...  симпсон уборка   \n",
       "4  дизайн halter neck loop strap detail ruged sid...         следует   \n",
       "\n",
       "          product_color  relevance  product_id  query_id  ... ctx_title_len  \\\n",
       "0  я не знаю что делать          0  B0066TUXU6      8677  ...           1.0   \n",
       "1               серебро          0  B07663TBC4     12307  ...          17.0   \n",
       "2                разряд          0  B06Y1CBVKT     66517  ...          12.0   \n",
       "3              оригинал          0  B004S67CUS     83198  ...           4.0   \n",
       "4          вино красное          0  B072BJPTKJ     14164  ...           7.0   \n",
       "\n",
       "  ctx_desc_len ctx_bullet_len  ctx_brand_in_title  ctx_color_in_title  \\\n",
       "0          5.0           65.0                   0                   0   \n",
       "1         47.0           49.0                   0                   0   \n",
       "2          5.0           28.0                   0                   0   \n",
       "3          5.0           29.0                   0                   0   \n",
       "4         60.0           52.0                   0                   0   \n",
       "\n",
       "   prod_count  prod_mean_rel  prod_max_rel  query_count  query_mean_rel  \n",
       "0         1.0            0.0           0.0          4.0            0.75  \n",
       "1         1.0            0.0           0.0          4.0            0.50  \n",
       "2         1.0            0.0           0.0          5.0            0.00  \n",
       "3         1.0            0.0           0.0          2.0            0.00  \n",
       "4         1.0            0.0           0.0          5.0            1.80  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 Unified product_text_clean\n",
    "def build_product_text_clean(df: pd.DataFrame) -> pd.Series:\n",
    "    parts = [\n",
    "        df[\"product_title\"],\n",
    "        df[\"product_description\"],\n",
    "        df[\"product_bullet_point\"],\n",
    "        df[\"product_brand\"],\n",
    "        df[\"product_color\"],\n",
    "    ]\n",
    "    return (\n",
    "        parts[0].fillna(\"\")\n",
    "        + \" [SEP] \" + parts[1].fillna(\"\")\n",
    "        + \" [SEP] \" + parts[2].fillna(\"\")\n",
    "        + \" [SEP] \" + parts[3].fillna(\"\")\n",
    "        + \" [SEP] \" + parts[4].fillna(\"\")\n",
    "    )\n",
    "\n",
    "esci_train[\"product_text_clean\"] = build_product_text_clean(esci_train)\n",
    "esci_test[\"product_text_clean\"]  = build_product_text_clean(esci_test)\n",
    "\n",
    "# 2.2 Explicit \"context\" features from metadata\n",
    "def add_context_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # --- Basic lengths ---\n",
    "    df[\"ctx_title_len\"]  = df[\"product_title\"].fillna(\"\").str.split().str.len().astype(\"float32\")\n",
    "    df[\"ctx_desc_len\"]   = df[\"product_description\"].fillna(\"\").str.split().str.len().astype(\"float32\")\n",
    "    df[\"ctx_bullet_len\"] = df[\"product_bullet_point\"].fillna(\"\").str.split().str.len().astype(\"float32\")\n",
    "\n",
    "    # Precompute lowercased strings\n",
    "    title_lower = df[\"product_title\"].fillna(\"\").str.lower()\n",
    "    brand_lower = df[\"product_brand\"].fillna(\"\").str.lower()\n",
    "    color_lower = df[\"product_color\"].fillna(\"\").str.lower()\n",
    "\n",
    "    # --- Brand in title (row-wise substring check) ---\n",
    "    df[\"ctx_brand_in_title\"] = [\n",
    "        int((b != \"\") and (b in t))\n",
    "        for b, t in zip(brand_lower, title_lower)\n",
    "    ]\n",
    "\n",
    "    # --- Color in title (row-wise substring check) ---\n",
    "    df[\"ctx_color_in_title\"] = [\n",
    "        int((c != \"\") and (c in t))\n",
    "        for c, t in zip(color_lower, title_lower)\n",
    "    ]\n",
    "\n",
    "    # Cast to int8 for compactness\n",
    "    df[\"ctx_brand_in_title\"] = df[\"ctx_brand_in_title\"].astype(\"int8\")\n",
    "    df[\"ctx_color_in_title\"] = df[\"ctx_color_in_title\"].astype(\"int8\")\n",
    "\n",
    "    return df\n",
    "\n",
    "esci_train = add_context_features(esci_train)\n",
    "esci_test  = add_context_features(esci_test)\n",
    "\n",
    "# 2.3 Popularity / behaviour proxies (within ESCI train)\n",
    "prod_stats = (\n",
    "    esci_train.groupby(\"product_id\")[\"relevance\"]\n",
    "    .agg(prod_count=\"size\", prod_mean_rel=\"mean\", prod_max_rel=\"max\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "query_stats = (\n",
    "    esci_train.groupby(\"query_id\")[\"relevance\"]\n",
    "    .agg(query_count=\"size\", query_mean_rel=\"mean\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "esci_train = esci_train.merge(prod_stats, on=\"product_id\", how=\"left\")\n",
    "esci_train = esci_train.merge(query_stats, on=\"query_id\", how=\"left\")\n",
    "\n",
    "# For test, merge stats computed from train only\n",
    "esci_test = esci_test.merge(prod_stats, on=\"product_id\", how=\"left\")\n",
    "esci_test = esci_test.merge(query_stats, on=\"query_id\", how=\"left\")\n",
    "\n",
    "# Fill NaNs for unseen products/queries in test\n",
    "pop_cols = [\"prod_count\", \"prod_mean_rel\", \"prod_max_rel\", \"query_count\", \"query_mean_rel\"]\n",
    "for col in pop_cols:\n",
    "    esci_train[col] = esci_train[col].fillna(0).astype(\"float32\")\n",
    "    esci_test[col]  = esci_test[col].fillna(0).astype(\"float32\")\n",
    "\n",
    "esci_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689d0a9a",
   "metadata": {},
   "source": [
    "# 3. Train/Valid Split (Grouped by query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0625cb36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:54:17.245059Z",
     "iopub.status.busy": "2025-11-25T07:54:17.244902Z",
     "iopub.status.idle": "2025-11-25T07:54:17.307999Z",
     "shell.execute_reply": "2025-11-25T07:54:17.307455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train / Valid shapes: (107125, 23) (11727, 23)\n"
     ]
    }
   ],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.1, random_state=RANDOM_STATE)\n",
    "train_idx, valid_idx = next(gss.split(esci_train, groups=esci_train[\"query_id\"]))\n",
    "\n",
    "train_df = esci_train.iloc[train_idx].reset_index(drop=True)\n",
    "valid_df = esci_train.iloc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "print(\"Train / Valid shapes:\", train_df.shape, valid_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297c67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9caf80b",
   "metadata": {},
   "source": [
    "# 4. BM25 Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87dc3ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:54:17.309781Z",
     "iopub.status.busy": "2025-11-25T07:54:17.309617Z",
     "iopub.status.idle": "2025-11-25T07:54:22.642808Z",
     "shell.execute_reply": "2025-11-25T07:54:22.642273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B08GD3D9YJ', 20.030306776196227), ('B07741VHLB', 17.961821098191628), ('B07P76HM3B', 17.919597956048662), ('B07X3LSNMQ', 17.87757285760172), ('B01FIS7AU6', 17.87757285760172)]\n"
     ]
    }
   ],
   "source": [
    "def build_bm25_corpus(df: pd.DataFrame):\n",
    "    # one doc per product_id\n",
    "    prod_group = df.groupby(\"product_id\")[\"product_text_clean\"].first()\n",
    "    product_ids = prod_group.index.to_list()\n",
    "    corpus = [doc.split() for doc in prod_group.values]\n",
    "    return product_ids, corpus\n",
    "\n",
    "bm25_product_ids, bm25_corpus = build_bm25_corpus(esci_train)\n",
    "bm25 = BM25Okapi(bm25_corpus)\n",
    "\n",
    "# Map product_id -> index in BM25 corpus\n",
    "prodid_to_idx = {pid: i for i, pid in enumerate(bm25_product_ids)}\n",
    "\n",
    "def bm25_candidates_for_query(query_text: str, top_k: int = 100):\n",
    "    tokenized = query_text.split()\n",
    "    scores = bm25.get_scores(tokenized)\n",
    "    top_idx = np.argsort(scores)[::-1][:top_k]\n",
    "    return [(bm25_product_ids[i], float(scores[i])) for i in top_idx]\n",
    "\n",
    "# Example sanity check\n",
    "print(bm25_candidates_for_query(esci_train[\"query\"].iloc[0], top_k=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "025917ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:54:22.644551Z",
     "iopub.status.busy": "2025-11-25T07:54:22.644390Z",
     "iopub.status.idle": "2025-11-25T07:54:34.202096Z",
     "shell.execute_reply": "2025-11-25T07:54:34.201426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved BM25 corpus to: esci_pipeline/artifacts_ru/bm25_corpus.pkl\n"
     ]
    }
   ],
   "source": [
    "# ---- SAVE BM25 corpus (optional but useful) ----\n",
    "import pickle\n",
    "\n",
    "with open(PATH_BM25_PKL, \"wb\") as f:\n",
    "    pickle.dump((bm25_product_ids, bm25_corpus), f)\n",
    "\n",
    "print(\"Saved BM25 corpus to:\", PATH_BM25_PKL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb8dbe",
   "metadata": {},
   "source": [
    "# 5. Attach BM25 Scores & Ranks to train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb2439d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:54:34.203894Z",
     "iopub.status.busy": "2025-11-25T07:54:34.203731Z",
     "iopub.status.idle": "2025-11-25T09:56:14.157770Z",
     "shell.execute_reply": "2025-11-25T09:56:14.157018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>bm25_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66517</td>\n",
       "      <td>7.621832</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  bm25_score  bm25_rank\n",
       "0      8677    0.000000          1\n",
       "1     12307    0.000000          1\n",
       "2     66517    7.621832          1\n",
       "3     83198    0.000000          1\n",
       "4     79687    0.000000          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attach_bm25_scores(df_queries: pd.DataFrame, top_k: int = 100) -> pd.DataFrame:\n",
    "    df_queries = df_queries.copy()\n",
    "    rows = []\n",
    "\n",
    "    for qid, sub in df_queries.groupby(\"query_id\"):\n",
    "        q_text = sub[\"query\"].iloc[0]\n",
    "        cand = bm25_candidates_for_query(q_text, top_k=top_k)\n",
    "        cand_map = {pid: score for pid, score in cand}\n",
    "        for idx, row in sub.iterrows():\n",
    "            pid = row[\"product_id\"]\n",
    "            bm25_score = cand_map.get(pid, 0.0)\n",
    "            rows.append((idx, bm25_score))\n",
    "\n",
    "    bm25_scores = pd.DataFrame(rows, columns=[\"row_idx\", \"bm25_score\"]).set_index(\"row_idx\")\n",
    "    df_queries = df_queries.join(bm25_scores, how=\"left\")\n",
    "    df_queries[\"bm25_score\"] = df_queries[\"bm25_score\"].fillna(0.0)\n",
    "\n",
    "    # Rank within each query (higher score = better rank)\n",
    "    df_queries[\"bm25_rank\"] = (\n",
    "        df_queries.groupby(\"query_id\")[\"bm25_score\"]\n",
    "        .rank(ascending=False, method=\"first\")\n",
    "        .astype(\"int32\")\n",
    "    )\n",
    "    return df_queries\n",
    "\n",
    "train_df = attach_bm25_scores(train_df, top_k=100)\n",
    "valid_df = attach_bm25_scores(valid_df, top_k=100)\n",
    "\n",
    "train_df[[\"query_id\", \"bm25_score\", \"bm25_rank\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf01ee",
   "metadata": {},
   "source": [
    "# 6. GTE Multilingual Embeddings & Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "398aa527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T09:56:14.159870Z",
     "iopub.status.busy": "2025-11-25T09:56:14.159689Z",
     "iopub.status.idle": "2025-11-25T10:02:41.584145Z",
     "shell.execute_reply": "2025-11-25T10:02:41.583294Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved product embeddings to: esci_pipeline/artifacts_ru/prod_embs.npy\n",
      "Saved product IDs to: esci_pipeline/artifacts_ru/product_ids.npy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>gte_score</th>\n",
       "      <th>gte_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8677</td>\n",
       "      <td>0.486179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12307</td>\n",
       "      <td>0.631867</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66517</td>\n",
       "      <td>0.615688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83198</td>\n",
       "      <td>0.548880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79687</td>\n",
       "      <td>0.422640</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  gte_score  gte_rank\n",
       "0      8677   0.486179         1\n",
       "1     12307   0.631867         2\n",
       "2     66517   0.615688         1\n",
       "3     83198   0.548880         2\n",
       "4     79687   0.422640         4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ---- CONFIG ----\n",
    "GTE_MODEL_NAME = \"Alibaba-NLP/gte-multilingual-base\"\n",
    "\n",
    "# Load model on correct device\n",
    "gte_model = SentenceTransformer(\n",
    "    GTE_MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    device=DEVICE,   # \"cuda\" or \"cpu\" from your earlier config\n",
    ")\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_texts(texts, batch_size=64):\n",
    "    # SentenceTransformer handles tokenization + model + pooling internally\n",
    "    embs = gte_model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,    # already L2-normalized -> cosine via dot product\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    return embs\n",
    "\n",
    "# 6.1 Precompute product embeddings (train universe)\n",
    "prod_group = esci_train.groupby(\"product_id\")[\"product_text_clean\"].first()\n",
    "product_ids = prod_group.index.to_list()\n",
    "prod_embs   = encode_texts(prod_group.tolist(), batch_size=64)\n",
    "\n",
    "prodid_to_emb = {pid: emb for pid, emb in zip(product_ids, prod_embs)}\n",
    "\n",
    "# ---- SAVE product embeddings + IDs ----\n",
    "np.save(PATH_PROD_EMBS, prod_embs)\n",
    "np.save(PATH_PROD_IDS, np.array(product_ids))\n",
    "\n",
    "print(\"Saved product embeddings to:\", PATH_PROD_EMBS)\n",
    "print(\"Saved product IDs to:\", PATH_PROD_IDS)\n",
    "\n",
    "\n",
    "# 6.2 Compute query embeddings for train/valid (correctly aligned)\n",
    "train_q = train_df.groupby(\"query_id\")[\"query\"].first().reset_index()\n",
    "valid_q = valid_df.groupby(\"query_id\")[\"query\"].first().reset_index()\n",
    "\n",
    "train_query_embs = encode_texts(train_q[\"query\"].tolist())\n",
    "valid_query_embs = encode_texts(valid_q[\"query\"].tolist())\n",
    "\n",
    "qid_to_emb_train = {\n",
    "    int(qid): emb for qid, emb in zip(train_q[\"query_id\"].tolist(), train_query_embs)\n",
    "}\n",
    "qid_to_emb_valid = {\n",
    "    int(qid): emb for qid, emb in zip(valid_q[\"query_id\"].tolist(), valid_query_embs)\n",
    "}\n",
    "\n",
    "\n",
    "def attach_gte_scores(df: pd.DataFrame, qid_to_emb: dict) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    scores = []\n",
    "    for idx, row in df.iterrows():\n",
    "        q_emb = qid_to_emb[int(row[\"query_id\"])]\n",
    "        p_emb = prodid_to_emb[row[\"product_id\"]]\n",
    "        score = float(np.dot(q_emb, p_emb))  # cosine because normalized\n",
    "        scores.append(score)\n",
    "\n",
    "    df[\"gte_score\"] = scores\n",
    "    df[\"gte_rank\"] = (\n",
    "        df.groupby(\"query_id\")[\"gte_score\"]\n",
    "        .rank(ascending=False, method=\"first\")\n",
    "        .astype(\"int32\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "train_df = attach_gte_scores(train_df, qid_to_emb_train)\n",
    "valid_df = attach_gte_scores(valid_df, qid_to_emb_valid)\n",
    "\n",
    "train_df[[\"query_id\", \"gte_score\", \"gte_rank\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda78ef",
   "metadata": {},
   "source": [
    "# 7. RRF Fusion Baseline (BM25 + GTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a93b3e12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T10:02:41.586545Z",
     "iopub.status.busy": "2025-11-25T10:02:41.586356Z",
     "iopub.status.idle": "2025-11-25T10:02:41.624419Z",
     "shell.execute_reply": "2025-11-25T10:02:41.623734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>rrf_score</th>\n",
       "      <th>rrf_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14164</td>\n",
       "      <td>0.031778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45325</td>\n",
       "      <td>0.032266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52411</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63949</td>\n",
       "      <td>0.032002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100206</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  rrf_score  rrf_rank\n",
       "0     14164   0.031778         2\n",
       "1     45325   0.032266         1\n",
       "2     52411   0.032258         2\n",
       "3     63949   0.032002         3\n",
       "4    100206   0.032522         1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rrf_fusion(bm25_rank, gte_rank, c: float = 60.0):\n",
    "    return 1.0 / (c + bm25_rank) + 1.0 / (c + gte_rank)\n",
    "\n",
    "for df in (train_df, valid_df):\n",
    "    df[\"rrf_score\"] = rrf_fusion(df[\"bm25_rank\"], df[\"gte_rank\"])\n",
    "    df[\"rrf_rank\"]  = (\n",
    "        df.groupby(\"query_id\")[\"rrf_score\"]\n",
    "        .rank(ascending=False, method=\"first\")\n",
    "        .astype(\"int32\")\n",
    "    )\n",
    "\n",
    "valid_df[[\"query_id\", \"rrf_score\", \"rrf_rank\"]].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3afc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46437662",
   "metadata": {},
   "source": [
    "# 8. MMR Baseline (Using GTE embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2848497f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T10:02:41.626390Z",
     "iopub.status.busy": "2025-11-25T10:02:41.626216Z",
     "iopub.status.idle": "2025-11-25T10:04:24.581162Z",
     "shell.execute_reply": "2025-11-25T10:04:24.580501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>mmr_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14164</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45325</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52411</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100206</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  mmr_rank\n",
       "0     14164         4\n",
       "1     45325         3\n",
       "2     52411         2\n",
       "3     63949         4\n",
       "4    100206         2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mmr_rerank(df_q: pd.DataFrame, lambda_: float = 0.7, top_k: int = 20) -> pd.DataFrame:\n",
    "    df_q = df_q.copy()\n",
    "    cand_idx = df_q.index.to_list()\n",
    "    selected = []\n",
    "    remaining = cand_idx.copy()\n",
    "\n",
    "    # Pre-collect product embeddings\n",
    "    pid_to_emb_local = {\n",
    "        pid: prodid_to_emb[pid] for pid in df_q[\"product_id\"].unique()\n",
    "    }\n",
    "\n",
    "    while remaining and len(selected) < top_k:\n",
    "        best_i = None\n",
    "        best_score = -1e9\n",
    "        for i in remaining:\n",
    "            row = df_q.loc[i]\n",
    "            rel = float(row[\"gte_score\"])\n",
    "            if not selected:\n",
    "                score = rel\n",
    "            else:\n",
    "                emb_i = pid_to_emb_local[row[\"product_id\"]]\n",
    "                max_sim = max(\n",
    "                    float(np.dot(emb_i, pid_to_emb_local[df_q.loc[j, \"product_id\"]]))\n",
    "                    for j in selected\n",
    "                )\n",
    "                score = lambda_ * rel - (1.0 - lambda_) * max_sim\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_i = i\n",
    "        selected.append(best_i)\n",
    "        remaining.remove(best_i)\n",
    "\n",
    "    # Build rank series for selected items\n",
    "    mmr_order = pd.Series(range(1, len(selected) + 1), index=selected)\n",
    "    df_q[\"mmr_rank\"] = (\n",
    "        df_q.index.to_series().map(mmr_order).fillna(len(df_q) + 1).astype(\"int32\")\n",
    "    )\n",
    "    return df_q\n",
    "\n",
    "def apply_mmr(df: pd.DataFrame, lambda_: float = 0.7, top_k: int = 20) -> pd.DataFrame:\n",
    "    parts = []\n",
    "    for qid, sub in df.groupby(\"query_id\"):\n",
    "        parts.append(mmr_rerank(sub, lambda_=lambda_, top_k=top_k))\n",
    "    return pd.concat(parts, axis=0).sort_index()\n",
    "\n",
    "train_df = apply_mmr(train_df, lambda_=0.7, top_k=20)\n",
    "valid_df = apply_mmr(valid_df, lambda_=0.7, top_k=20)\n",
    "\n",
    "# Convert MMR ranks into scores for evaluation\n",
    "for df in (train_df, valid_df):\n",
    "    # Lower rank = better item => use negative rank as score\n",
    "    df[\"mmr_score\"] = -df[\"mmr_rank\"].astype(\"float32\")\n",
    "\n",
    "\n",
    "valid_df[[\"query_id\", \"mmr_rank\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc4d844",
   "metadata": {},
   "source": [
    "# 9. LambdaMART (Context-Aware LTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a66bc681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T10:04:24.583073Z",
     "iopub.status.busy": "2025-11-25T10:04:24.582908Z",
     "iopub.status.idle": "2025-11-25T10:04:56.790025Z",
     "shell.execute_reply": "2025-11-25T10:04:56.789341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LightGBM LambdaMART model to: esci_pipeline/artifacts_ru/ltr_model_us.txt\n",
      "Saved prepared train_df to: esci_pipeline/artifacts_ru/train_df_prepared.parquet\n",
      "Saved prepared valid_df to: esci_pipeline/artifacts_ru/valid_df_prepared.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>ltr_score</th>\n",
       "      <th>ltr_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2.121644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>-2.087208</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>-2.087208</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>-2.087208</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>1.388797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  ltr_score  ltr_rank\n",
       "0         8   2.121644         1\n",
       "1        70  -2.087208         3\n",
       "2        70  -2.087208         4\n",
       "3        70  -2.087208         5\n",
       "4        70   1.388797         1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: sort by query_id so LightGBM group sizes match row order\n",
    "train_df = train_df.sort_values(\"query_id\").reset_index(drop=True)\n",
    "valid_df = valid_df.sort_values(\"query_id\").reset_index(drop=True)\n",
    "\n",
    "ltr_features = [\n",
    "    \"bm25_score\",\n",
    "    \"gte_score\",\n",
    "    \"ctx_title_len\",\n",
    "    \"ctx_desc_len\",\n",
    "    \"ctx_bullet_len\",\n",
    "    \"ctx_brand_in_title\",\n",
    "    \"ctx_color_in_title\",\n",
    "    \"prod_count\",\n",
    "    \"prod_mean_rel\",\n",
    "    \"prod_max_rel\",\n",
    "    \"query_count\",\n",
    "    \"query_mean_rel\",\n",
    "]\n",
    "\n",
    "X_train = train_df[ltr_features].astype(\"float32\")\n",
    "y_train = train_df[\"relevance\"].astype(\"float32\")\n",
    "group_train = train_df.groupby(\"query_id\").size().to_list()\n",
    "\n",
    "X_valid = valid_df[ltr_features].astype(\"float32\")\n",
    "y_valid = valid_df[\"relevance\"].astype(\"float32\")\n",
    "group_valid = valid_df.groupby(\"query_id\").size().to_list()\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train, group=group_train)\n",
    "lgb_valid = lgb.Dataset(X_valid, label=y_valid, group=group_valid, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"ndcg_eval_at\": [10],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 63,\n",
    "    \"min_data_in_leaf\": 50,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "}\n",
    "\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "]\n",
    "\n",
    "lgbm_model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    num_boost_round=300,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# ---- SAVE LTR model ----\n",
    "lgbm_model.save_model(str(PATH_LGB_MODEL))\n",
    "print(\"Saved LightGBM LambdaMART model to:\", PATH_LGB_MODEL)\n",
    "\n",
    "# 9.1 Predict LTR scores\n",
    "valid_df[\"ltr_score\"] = lgbm_model.predict(\n",
    "    X_valid,\n",
    "    num_iteration=lgbm_model.best_iteration\n",
    ")\n",
    "valid_df[\"ltr_rank\"]  = (\n",
    "    valid_df.groupby(\"query_id\")[\"ltr_score\"]\n",
    "    .rank(ascending=False, method=\"first\")\n",
    "    .astype(\"int32\")\n",
    ")\n",
    "\n",
    "# ---- SAVE prepared train/valid DataFrames ----\n",
    "train_df.to_parquet(PATH_TRAIN_PREP, index=False)\n",
    "valid_df.to_parquet(PATH_VALID_PREP, index=False)\n",
    "\n",
    "print(\"Saved prepared train_df to:\", PATH_TRAIN_PREP)\n",
    "print(\"Saved prepared valid_df to:\", PATH_VALID_PREP)\n",
    "\n",
    "\n",
    "valid_df[[\"query_id\", \"ltr_score\", \"ltr_rank\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915b2d2f",
   "metadata": {},
   "source": [
    "# 10. Cross-Encoder (DistilBERT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b06e20a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T10:04:56.791973Z",
     "iopub.status.busy": "2025-11-25T10:04:56.791803Z",
     "iopub.status.idle": "2025-11-25T10:18:31.917749Z",
     "shell.execute_reply": "2025-11-25T10:18:31.917029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f385857ed894431f8045e37152c1d5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/107125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ff00ef70c648b0b05e834e023be8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13392' max='13392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13392/13392 12:56, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.146200</td>\n",
       "      <td>1.216767</td>\n",
       "      <td>0.460817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.008400</td>\n",
       "      <td>1.240577</td>\n",
       "      <td>0.462352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_hf_dataset(df: pd.DataFrame) -> Dataset:\n",
    "    tmp = df[[\"query\", \"product_text_clean\", \"relevance\"]].rename(\n",
    "        columns={\"relevance\": \"label\"}\n",
    "    )\n",
    "    # preserve_index=False avoids keeping the Pandas index as a separate column\n",
    "    return Dataset.from_pandas(tmp, preserve_index=False)\n",
    "\n",
    "train_hf = make_hf_dataset(train_df)\n",
    "valid_hf = make_hf_dataset(valid_df)\n",
    "\n",
    "tokenizer_x = AutoTokenizer.from_pretrained(XENC_MODEL_NAME)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    enc = tokenizer_x(\n",
    "        batch[\"query\"],\n",
    "        batch[\"product_text_clean\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "    enc[\"labels\"] = batch[\"label\"]\n",
    "    return enc\n",
    "\n",
    "train_tok = train_hf.map(tokenize_batch, batched=True)\n",
    "valid_tok = valid_hf.map(tokenize_batch, batched=True)\n",
    "\n",
    "train_tok = train_tok.remove_columns([\"query\", \"product_text_clean\"])\n",
    "valid_tok = valid_tok.remove_columns([\"query\", \"product_text_clean\"])\n",
    "\n",
    "train_tok.set_format(\"torch\")\n",
    "valid_tok.set_format(\"torch\")\n",
    "\n",
    "# 10.1 Model (4-class classification)\n",
    "num_labels = 4\n",
    "xenc_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    XENC_MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"single_label_classification\",\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/esci_ru_xenc\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = (preds == labels).mean()\n",
    "    return {\"accuracy\": float(acc)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=xenc_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=valid_tok,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 10.2 Getting CE scores for valid_df after training:\n",
    "preds = trainer.predict(valid_tok)\n",
    "logits = preds.predictions\n",
    "probs  = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "valid_df[\"ce_score\"] = probs[:, 3] + 0.5 * probs[:, 2]  # weight Exact/Substitute\n",
    "valid_df[\"ce_rank\"]  = (\n",
    "    valid_df.groupby(\"query_id\")[\"ce_score\"]\n",
    "    .rank(ascending=False, method=\"first\")\n",
    "    .astype(\"int32\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879891c",
   "metadata": {},
   "source": [
    "# 11. Evaluation (nDCG@K, P@K, gAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1032107",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T10:18:31.920008Z",
     "iopub.status.busy": "2025-11-25T10:18:31.919658Z",
     "iopub.status.idle": "2025-11-25T10:18:44.452535Z",
     "shell.execute_reply": "2025-11-25T10:18:44.451771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bm25_score {'nDCG@10': 0.8227796126522215, 'P@10': 0.7967030234930966, 'gAUC': 0.5613473469004544}\n",
      "gte_score {'nDCG@10': 0.8341365994421416, 'P@10': 0.7970284913531456, 'gAUC': 0.673097280897177}\n",
      "rrf_score {'nDCG@10': 0.8095151172074682, 'P@10': 0.7963978973743009, 'gAUC': 0.5501003768398196}\n",
      "ltr_score {'nDCG@10': 0.875690271497968, 'P@10': 0.7974963514019657, 'gAUC': 0.9674200779841008}\n",
      "mmr_score {'nDCG@10': 0.8339985160560252, 'P@10': 0.7967437069756029, 'gAUC': 0.5851658804968771}\n",
      "ce_score {'nDCG@10': 0.829542576333774, 'P@10': 0.7966013147868315, 'gAUC': 0.6098408506376989}\n"
     ]
    }
   ],
   "source": [
    "def dcg_at_k(rels, k: int):\n",
    "    rels = np.asarray(rels)[:k]\n",
    "    if rels.size == 0:\n",
    "        return 0.0\n",
    "    discounts = np.log2(np.arange(2, rels.size + 2))\n",
    "    return float(np.sum((2 ** rels - 1) / discounts))\n",
    "\n",
    "def ndcg_at_k(rels, k: int):\n",
    "    rels = np.asarray(rels)\n",
    "    best = np.sort(rels)[::-1]\n",
    "    best_dcg = dcg_at_k(best, k)\n",
    "    if best_dcg == 0:\n",
    "        return 0.0\n",
    "    return dcg_at_k(rels, k) / best_dcg\n",
    "\n",
    "def eval_ranking(df: pd.DataFrame, score_col: str, k: int = 10):\n",
    "    ndcgs = []\n",
    "    precs = []\n",
    "    auc_labels = []\n",
    "    auc_scores = []\n",
    "\n",
    "    for qid, sub in df.groupby(\"query_id\"):\n",
    "        sub_sorted = sub.sort_values(score_col, ascending=False)\n",
    "        rels = sub_sorted[\"relevance\"].values\n",
    "\n",
    "        ndcgs.append(ndcg_at_k(rels, k))\n",
    "        precs.append((rels[:k] > 0).mean())  # non-zero relevance => positive\n",
    "\n",
    "        auc_labels.extend((rels > 0).astype(int).tolist())\n",
    "        auc_scores.extend(sub_sorted[score_col].tolist())\n",
    "\n",
    "    ndcg = float(np.mean(ndcgs))\n",
    "    prec = float(np.mean(precs))\n",
    "    try:\n",
    "        gauc = float(roc_auc_score(auc_labels, auc_scores))\n",
    "    except ValueError:\n",
    "        gauc = float(\"nan\")\n",
    "\n",
    "    return {\"nDCG@{}\".format(k): ndcg, \"P@{}\".format(k): prec, \"gAUC\": gauc}\n",
    "\n",
    "for col in [\"bm25_score\", \"gte_score\", \"rrf_score\", \"ltr_score\",\"mmr_score\", \"ce_score\"]:\n",
    "    metrics = eval_ranking(valid_df, col, k=10)\n",
    "    print(col, metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0c0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef4e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658c20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b14a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f64b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de3b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027c210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d63e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895d5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c3458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcf2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e9fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3d733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0547b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271d043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8ff74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (TF)",
   "language": "python",
   "name": "tf-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0302bc4c5bce4856ab2f22658697bc0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d3be06bb29147339217c43093db504f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0da27c728f8a434e82cf1ec1cc44951b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0e3cdffff2174dbd9be2c10b695a02e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ddc3ab52b81464c8d2718290b2f92ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2f9955e534894c5994a150a929d88b04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ac64858b68214d72900db762cd7a642c",
       "placeholder": "​",
       "style": "IPY_MODEL_2ddc3ab52b81464c8d2718290b2f92ea",
       "tabbable": null,
       "tooltip": null,
       "value": " 11727/11727 [00:01&lt;00:00, 8579.12 examples/s]"
      }
     },
     "44eab63b05cf4298bfd03b0691bc1133": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51060dd13ac144eba8a6126e4761af71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "62ff00ef70c648b0b05e834e023be8e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fa5268b470274558b3d562ae40d35eda",
        "IPY_MODEL_c8258679815b4a03ad3129e4040fdd1c",
        "IPY_MODEL_2f9955e534894c5994a150a929d88b04"
       ],
       "layout": "IPY_MODEL_0d3be06bb29147339217c43093db504f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6fa6652f4be74a66a8d9540d231eb380": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9fac1fbc378643e3a9ca56f9a8879d93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ac64858b68214d72900db762cd7a642c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af07d54a98c64b98843568383fed8791": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf70443d945440ffadcebbf80303c1fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_44eab63b05cf4298bfd03b0691bc1133",
       "placeholder": "​",
       "style": "IPY_MODEL_0da27c728f8a434e82cf1ec1cc44951b",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "c8258679815b4a03ad3129e4040fdd1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0e3cdffff2174dbd9be2c10b695a02e7",
       "max": 11727,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9fac1fbc378643e3a9ca56f9a8879d93",
       "tabbable": null,
       "tooltip": null,
       "value": 11727
      }
     },
     "e0113c2744ec425eaea16cf2c4452136": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e23aae0918f4485bb60af56abde1774c",
       "max": 107125,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_51060dd13ac144eba8a6126e4761af71",
       "tabbable": null,
       "tooltip": null,
       "value": 107125
      }
     },
     "e23aae0918f4485bb60af56abde1774c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e52561d45ecd473a9118c1999c37f593": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e65ea457c4bb47ee83cd3f6bd8c4e468": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0302bc4c5bce4856ab2f22658697bc0e",
       "placeholder": "​",
       "style": "IPY_MODEL_e52561d45ecd473a9118c1999c37f593",
       "tabbable": null,
       "tooltip": null,
       "value": " 107125/107125 [00:12&lt;00:00, 8741.42 examples/s]"
      }
     },
     "f385857ed894431f8045e37152c1d5cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bf70443d945440ffadcebbf80303c1fb",
        "IPY_MODEL_e0113c2744ec425eaea16cf2c4452136",
        "IPY_MODEL_e65ea457c4bb47ee83cd3f6bd8c4e468"
       ],
       "layout": "IPY_MODEL_fc2e539615b040d08cad81e24ca88a10",
       "tabbable": null,
       "tooltip": null
      }
     },
     "fa5268b470274558b3d562ae40d35eda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_af07d54a98c64b98843568383fed8791",
       "placeholder": "​",
       "style": "IPY_MODEL_6fa6652f4be74a66a8d9540d231eb380",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "fc2e539615b040d08cad81e24ca88a10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
